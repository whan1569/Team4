온디바이스(On-Device) AI 실행 전략
1. 경량화된 온디바이스 AI 모델
TensorFlow Lite 또는 ONNX Runtime으로 모델 경량화.
Quantization(비트 정밀도로 변환)과 Pruning(불필요 뉴런 제거)으로 크기와 속도 최적화.
GPU/NPU 하드웨어 가속을 활용해 성능 극대화.
2. 암호화된 모델 파일
AES-256 암호화로 모델 파일 보호.
앱 실행 시 런타임에 복호화, 복호화 키는 앱에 저장하지 않고 서버에서 전달받거나 Secure Enclave를 활용.
3. 네이티브 실행 환경 활용
React Native 대신 **네이티브 모듈(Android: Java/Kotlin, iOS: Swift/Objective-C)**에서 실행.
자바스크립트보다 빠른 실행 속도와 보안성 제공.
React Native와 네이티브 모듈 간 브릿지를 통해 앱 기능과 통합.
4. 코드 난독화 및 조각화
react-native-obfuscator로 코드 난독화하여 리버스 엔지니어링 방지.
모델 파일을 여러 조각으로 나눠 포함, 실행 시 조합하도록 구현해 분석 난이도 증가.
5. 앱 인증과 라이센싱
앱 실행 시 서버 인증 절차를 통해 AI 기능 활성화.
특정 디바이스나 사용자에만 AI 기능 제한(인증 키, 라이센스 키 활용).
